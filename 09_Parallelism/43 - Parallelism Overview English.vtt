WEBVTT

0
00:00.150 --> 00:00.700
Hello again!

1
00:00.930 --> 00:04.590
In this video, we are going to have a quick overview of parallelism.

2
00:07.590 --> 00:13.770
People often use "concurrency" and "parallelism" to describe the same thing,
but there is actually an important

3
00:13.770 --> 00:14.730
difference between them.

4
00:15.120 --> 00:19.120
With concurrency, you have tasks which are conceptually distinct.

5
00:19.560 --> 00:22.200
So these are different threads which are doing different things.

6
00:22.980 --> 00:25.260
This is what is known as separation of concerns.

7
00:25.710 --> 00:30.540
So, for example, having the GUI application where we have one thread which handles events and other threads

8
00:30.960 --> 00:32.520
which handle various tasks.

9
00:33.300 --> 00:37.410
And it is possible for a concurrent program to run on a single processor core.

10
00:40.120 --> 00:46.660
These tasks are usually interactive.
They can often wait for an event or they can wait for other tasks

11
00:46.840 --> 00:53.440
to complete or to do something, and they can also exchange data with each other.
When it comes down

12
00:53.440 --> 00:53.710
to it,

13
00:53.770 --> 00:56.510
concurrency is really a feature of the program structure.

14
00:56.680 --> 01:00.000
It is the way you design the program, to separate concerns.

15
01:02.520 --> 01:07.400
When you have parallelism, on the other hand, you have many instances of the same task of running

16
01:07.420 --> 01:08.280
at the same time.

17
01:09.560 --> 01:13.940
So all these tasks are basically doing the same thing,
but they are running on multiple cores at the

18
01:13.940 --> 01:20.120
same time to improve scalability.
And these tasks are usually pretty much independent of each other.

19
01:21.710 --> 01:25.730
Parallelism is a feature of the algorithm that is being performed.

20
01:26.240 --> 01:31.200
There are some algorithms where it naturally makes sense to divide the data into different groups and

21
01:31.200 --> 01:33.860
then have each group processed at the same time.

22
01:34.910 --> 01:37.280
There is actually a very good sporting analogy.

23
01:39.020 --> 01:44.290
Concurrency is like a team sport, so everyone has a distinct role.

24
01:44.720 --> 01:47.090
Usually players are doing different things.

25
01:47.270 --> 01:48.590
They interact with each other.

26
01:49.070 --> 01:50.540
They wait to get the ball.

27
01:50.540 --> 01:52.700
They wait for other players to go into position.

28
01:53.810 --> 01:55.850
They wait for various events to happen and so on.

29
01:56.720 --> 01:59.960
Parallelism is more like an individual track sport.

30
02:00.440 --> 02:06.580
So, for example, sprinting, swimming and so on, everyone is doing the same thing
and they are all

31
02:06.620 --> 02:08.270
trying to do it as fast as possible.

32
02:08.510 --> 02:11.390
And there is no interaction between them or very little.

33
02:14.420 --> 02:21.620
There are two different ways of doing parallelism, explicit and implicit.
When you do it explicitly,

34
02:21.770 --> 02:25.610
you specify how exactly it should be done in parallel.

35
02:26.450 --> 02:32.000
For example, you divide your data into four parts and you start up four threads, each of which will

36
02:32.000 --> 02:33.890
process one quarter of the data.

37
02:35.390 --> 02:39.320
This involves more work for the programmer, but it can produce better performance.

38
02:40.640 --> 02:42.400
The problem is it is not scalable.

39
02:42.680 --> 02:47.000
If you have a machine which supports four threads and you have four threads,
then it is working flat

40
02:47.000 --> 02:47.300
out.

41
02:47.870 --> 02:53.000
If you buy a new computer which has support for eight threads,
then you are still only running four

42
02:53.000 --> 02:53.480
threads.

43
02:54.200 --> 02:58.630
So your program still runs at the same speed, even though you have twice as much processing capacity.

44
03:00.140 --> 03:05.960
One of the main situations where you would use this is if you are writing for a specific bit of hardware,

45
03:06.260 --> 03:08.360
A good example of that is a game console.

46
03:08.930 --> 03:12.680
Each generation of game consoles has a fixed number of processors.

47
03:13.070 --> 03:16.970
So you can actually tune your program for the number of processors.

48
03:19.030 --> 03:25.000
It is also useful if the problem you are trying to solve naturally divides into a fixed number of tasks.

49
03:28.180 --> 03:31.160
The other form of parallelism is implicit.

50
03:31.600 --> 03:36.760
This is where the programmer does not do anything, you just leave it up to the compiler and the environment

51
03:36.760 --> 03:37.990
to decide how to do it.

52
03:38.590 --> 03:42.810
And this means that you will always make the best use of the resources that are available.

53
03:44.660 --> 03:51.070
In the situation where you go from having a computer with four processor cores to having eight, then

54
03:51.080 --> 03:55.700
implicit parallelism means that you will automatically get eight threads instead of four.

55
03:57.110 --> 04:00.260
And for most purposes, this is the best option.

56
04:01.100 --> 04:02.810
Okay, so that's it for this video.

57
04:02.870 --> 04:03.740
I'll see you next time.

58
04:03.780 --> 04:05.840
But meanwhile, keep coding!