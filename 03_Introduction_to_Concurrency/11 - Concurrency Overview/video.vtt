WEBVTT

0
00:00.180 --> 00:00.780
Hello there.

1
00:01.320 --> 00:06.420
In this video, we're going to have an overview of concurrency. So this is basically going to look

2
00:06.420 --> 00:13.440
at some of the points made in previous videos in a little bit more detail. At the application level,

3
00:13.680 --> 00:21.030
concurrency can be done by having lots of separate programs representing different activities, which

4
00:21.030 --> 00:28.860
is single threading, or it can have one single executing program in which all the activities are performed,

5
00:30.100 --> 00:34.100
some of them at the same time, or even maybe all of them at the same time.

6
00:34.440 --> 00:35.730
And that's multi threading.

7
00:38.880 --> 00:44.760
Single threaded concurrency is the oldest and the original, a separate process for each activity,

8
00:45.000 --> 00:51.010
which has its own execution path through the source code, which is also known as a thread.

9
00:51.690 --> 00:55.620
So if you imagine you have the program's source code and you have a little...

10
00:57.070 --> 01:01.950
Is it the Greek legend with the Minotaur? He had the thread and he found his way out of the maze.

11
01:02.850 --> 01:07.560
So this is how the program traces its way through the maze of the program's code.

12
01:08.730 --> 01:11.420
So in single threading, each program only has one thread.

13
01:11.460 --> 01:16.440
There's just one way: to start at the beginning, go through to the end and then stop.

14
01:17.400 --> 01:24.990
Each process also has its own private memory space, so it's not possible for another process to directly

15
01:24.990 --> 01:27.270
access the data inside a process.

16
01:29.910 --> 01:33.750
We start up a new process for each activity so they can run concurrently.

17
01:33.760 --> 01:35.970
That's organized by the operating system.

18
01:37.810 --> 01:44.290
We start up a new process for each activity and the operating system will take care and make sure they

19
01:44.290 --> 01:45.230
run concurrently.

20
01:47.230 --> 01:54.040
If any of our activities need to exchange data or communicate in some way with each other, this will

21
01:54.040 --> 01:56.650
need some kind of interprocess communication.

22
01:58.270 --> 02:01.110
And there are various ways of doing that: message

23
02:01.120 --> 02:07.420
queue, pipe,  semaphore, shared memory, network socket,  file handles and so on.

24
02:08.620 --> 02:15.640
If we have a very simple system where we have one program that does lots of computations, that take a

25
02:15.640 --> 02:21.280
long time and make it unresponsive, and we want to be able to display an hourglass just to let the

26
02:21.280 --> 02:27.280
user know that we haven't forgotten them, then this program will need to start up a separate program

27
02:27.280 --> 02:29.140
to display the hourglass.

28
02:30.570 --> 02:38.070
It will also need to provide some kind of communication channel so it can tell the hourglass to stop, then

29
02:38.070 --> 02:43.860
when the data cruncher has finished crunching its data, it will send a message to the hourglass and

30
02:44.100 --> 02:49.610
the hourglass will stop running and the data cruncher can start reacting again.

31
02:54.750 --> 03:01.400
Each process has its own private space and cannot accidentally interfere with another process's data.

32
03:03.310 --> 03:10.350
A good feature of this is that process can be run on different computers, communicating over a network, so

33
03:10.350 --> 03:13.910
you can have a computer that is dedicated to a particular activity.

34
03:15.900 --> 03:19.100
Creating new processes can be slow on some systems.

35
03:20.410 --> 03:26.320
Interprocess communication adds complexity and can be slow to set up, and if you are working in C++,

36
03:26.680 --> 03:28.690
there's no direct support for this.

37
03:30.440 --> 03:37.070
You have to drop down to the operating system and use whatever facilities are available, so that's

38
03:37.070 --> 03:42.120
a lot of extra work and it means your program will not work if you try to run it on a different system.

39
03:45.500 --> 03:51.980
With multithreaded concurrency, we have all the activities running in a single process. Each activity

40
03:52.340 --> 03:55.190
has its own execution path or thread.

41
03:55.490 --> 04:01.040
So you can imagine there are several different threads making their way through the program code, at the

42
04:01.040 --> 04:05.870
same time, going in different directions, doing different things, or maybe even doing the same thing.

43
04:08.600 --> 04:15.470
To start a new activity, we create a new thread, so that's concurrency. All the threads

44
04:15.500 --> 04:18.470
share the memory space of the process they are running in.

45
04:19.460 --> 04:26.540
If we make any data global in this process, then all the threads can see it and access it and modify

46
04:26.540 --> 04:26.700
it.

47
04:27.590 --> 04:31.790
It's also possible to pass certain types of objects between threads.

48
04:33.320 --> 04:38.510
So if we go back to our data crunching example, we have one program that does everything.

49
04:40.040 --> 04:47.760
So this program will start off in main() executing the main thread. When it is about to start a long computation,

50
04:48.320 --> 04:51.440
it will start a new thread which will display the hourglass.

51
04:52.460 --> 04:58.130
And then when this computation is finished, it will terminate the hourglass thread and it will carry

52
04:58.130 --> 04:59.450
on executing.

53
05:04.020 --> 05:08.270
Threads are implemented using so-called lightweight processes.

54
05:09.240 --> 05:14.430
These are provided by the operating system. There is less overhead involved in creating a thread than

55
05:14.430 --> 05:16.440
there is in creating a full process.

56
05:17.100 --> 05:23.580
And there is also less overhead for task switching between threads because there's not so much to set

57
05:23.580 --> 05:24.540
up and switch.

58
05:26.240 --> 05:32.840
And sharing data and communication between threads is much easier than for processes. On the other

59
05:32.840 --> 05:34.400
hand, there is a lack of data protection.

60
05:35.150 --> 05:36.920
This can require careful programming.

61
05:37.500 --> 05:43.640
If you're not careful, you can corrupt your data and your program will behave inconsistently.

62
05:44.030 --> 05:46.250
And this is a big problem in threaded programming.

63
05:49.290 --> 05:55.800
The advantages of concurrency. The program will feel more responsive: if it is doing something and

64
05:55.800 --> 05:58.860
it gets busy, it will still respond to your commands.

65
06:00.900 --> 06:06.680
Concurrency can improve throughput by allowing large amounts of data or computation to be done at the same

66
06:06.680 --> 06:07.060
time.

67
06:09.220 --> 06:11.260
Which means less time overall.

68
06:12.730 --> 06:16.960
Concurrency allows logically distinct operations to be kept separate.

69
06:17.620 --> 06:25.270
If you are in an e-mail program and you are composing a new message, then other threads can run to fetch

70
06:25.450 --> 06:28.640
messages or perhaps archive your old messages.

71
06:30.620 --> 06:36.460
And it takes full advantage of modern hardware. Threads can be distributed among processor cores,

72
06:36.470 --> 06:38.500
so each thread runs on a separate core.

73
06:40.000 --> 06:43.540
And that will make much better use of the power that modern computers offer us.

74
06:46.520 --> 06:50.480
The disadvantages are that concurrency adds complexity to programs.

75
06:51.250 --> 06:53.100
It takes more thought to write them.

76
06:53.660 --> 06:57.850
They are harder to write, harder to understand, so more difficult to maintain.

77
06:58.700 --> 07:04.310
And there are also types of bugs which you do not get when there is only one thing happening.

78
07:04.730 --> 07:09.650
When you have multiple things happening at once, you can get issues which depend on timing, which

79
07:09.650 --> 07:13.130
are very hard to debug. Concurrency

80
07:13.130 --> 07:19.010
may not necessarily result in faster programs. By the time you have taken all this extra effort to

81
07:19.010 --> 07:20.210
protect your shared data,

82
07:20.710 --> 07:23.240
it may actually add more overhead than you are removing.

83
07:25.140 --> 07:27.520
So only use it when the benefits outweigh the costs.

84
07:28.620 --> 07:30.390
OK, so that's it for this video.

85
07:30.450 --> 07:31.380
I'll see you next time.